{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED=185"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import tree\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA='data/mamografias.csv'\n",
    "\n",
    "# Función para leer los datos\n",
    "def readData(data_file):\n",
    "    return pd.read_csv(data_file,sep=',', na_values='?')\n",
    "\n",
    "data = readData(DATA) # Lectura de los datos\n",
    "\n",
    "data.rename(columns = {'BI-RADS':'BiRads'}, inplace = True) # Para poder referirnos a esta columna como data.BiRads\n",
    "data.BiRads.replace(0,pd.NA,inplace=True) # BiRads 0 significa radiografía insuficiente\n",
    "data.Shape.replace('N',pd.NA,inplace=True) # Lo mismo pasa con Shape N\n",
    "data.replace(pd.NA, np.nan, inplace=True)\n",
    "\n",
    "data=data.dropna() # Eliminamos las instancias con valores perdidos\n",
    "data.shape[0] # Nos quedamos con 825 instancias\n",
    "\n",
    "# La distribución de la característica densidad es prácticamente degenerada en 3\n",
    "data.drop('Density', axis='columns',inplace=True)\n",
    "data.BiRads=data.BiRads.replace(6,5).replace(2,4).replace(3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['benigno' 'maligno']\n"
     ]
    }
   ],
   "source": [
    "# Sklearn necesita datos numéricos (aunque sean nominales)\n",
    "le = preprocessing.LabelEncoder()\n",
    "data.Shape = le.fit_transform(data.Shape)\n",
    "data.Severity = le.fit_transform(data.Severity)\n",
    "print(le.inverse_transform([0,1])) # Consideraremos maligno como la clase positiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['BiRads', 'Age', 'Shape', 'Margin', 'Severity'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5., 67.,  1.,  5.,  1.],\n",
       "       [ 5., 58.,  0.,  5.,  1.],\n",
       "       [ 4., 28.,  3.,  1.,  0.],\n",
       "       ...,\n",
       "       [ 4., 64.,  0.,  5.,  0.],\n",
       "       [ 5., 66.,  0.,  5.,  1.],\n",
       "       [ 4., 62.,  1.,  3.,  0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataArray=np.array(data)\n",
    "print(data.columns)\n",
    "dataArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Separamos en datos y target (label)\n",
    "x=dataArray[:,:-1]\n",
    "y=dataArray[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(825, 9)\n",
      "[[0. 1. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [1. 0. 0. ... 0. 0. 1.]\n",
      " [0. 1. 0. ... 1. 0. 0.]]\n",
      "(825, 11)\n",
      "[[ 5. 67.  0. ...  0.  0.  1.]\n",
      " [ 5. 58.  1. ...  0.  0.  1.]\n",
      " [ 4. 28.  0. ...  0.  0.  0.]\n",
      " ...\n",
      " [ 4. 64.  1. ...  0.  0.  1.]\n",
      " [ 5. 66.  1. ...  0.  0.  1.]\n",
      " [ 4. 62.  0. ...  1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "# Binarización de los atributos nominales\n",
    "x_nom=x[:,2:4] # Columnas con variables nominales: Shape y Margin\n",
    "x=np.delete(x,[2,3],axis=1) # Elimino las columnas\n",
    "onehot = preprocessing.OneHotEncoder(sparse=False)\n",
    "x_nom = onehot.fit_transform(x_nom)\n",
    "print(x_nom.shape)\n",
    "print(x_nom)\n",
    "x=np.hstack((x,x_nom))\n",
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para calcular la matriz de confusión usando validación cruzada sumamos las matrices obtenidas en las distintas particiones\n",
    "# https://stats.stackexchange.com/questions/147175/how-is-the-confusion-matrix-reported-from-k-fold-cross-validation\n",
    "# https://stackoverflow.com/questions/40057049/using-confusion-matrix-as-scoring-metric-in-cross-validation-in-scikit-learn\n",
    "def KFoldConfusionMatrix(model, data, target):\n",
    "    conf_matrix_list_of_arrays = []\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        X_train, X_test = data[train_index], data[test_index]\n",
    "        y_train, y_test = target[train_index], target[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        conf_matrix = confusion_matrix(y_test, model.predict(X_test))\n",
    "        conf_matrix_list_of_arrays.append(conf_matrix)\n",
    "    return np.sum(conf_matrix_list_of_arrays, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" La matriz de confusión aparece como\n",
    "          Pred:    0  1\n",
    "(Benigno) Real=0: TN FP\n",
    "(Maligno) Real=1: FN TP\n",
    "\"\"\"\n",
    "# Quiero ponerla: TP, TN, FP, FN\n",
    "def mcToArray(mc):\n",
    "    return ', '.join(list(map(str,[mc[1][1], mc[0][0], mc[0][1], mc[1][0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 425]\n",
      " [  0 400]]\n"
     ]
    }
   ],
   "source": [
    "# Dummy: siempre maligno (aunque benigno sea más frecuente)\n",
    "dummy=DummyClassifier(strategy='constant',constant=1)\n",
    "dummy_cf=KFoldConfusionMatrix(dummy, x, y)\n",
    "print(dummy_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[347  78]\n",
      " [103 297]]\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "dt=tree.DecisionTreeClassifier(random_state=SEED)\n",
    "dt_cf=KFoldConfusionMatrix(dt, x, y)\n",
    "print(dt_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[321 104]\n",
      " [ 46 354]]\n"
     ]
    }
   ],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gnb=GaussianNB()\n",
    "gnb_cf=KFoldConfusionMatrix(gnb, x, y)\n",
    "print(gnb_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[326  99]\n",
      " [ 64 336]]\n"
     ]
    }
   ],
   "source": [
    "# Multinomial Naive Bayes\n",
    "mnb=MultinomialNB()\n",
    "mnb_cf=KFoldConfusionMatrix(mnb, x, y)\n",
    "print(mnb_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[344  81]\n",
      " [ 81 319]]\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf=RandomForestClassifier(n_jobs=4, random_state=SEED)\n",
    "rf_cf=KFoldConfusionMatrix(rf, x, y)\n",
    "print(rf_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332  93]\n",
      " [ 68 332]]\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "knn=KNeighborsClassifier() # K=5 por defecto\n",
    "knn_cf=KFoldConfusionMatrix(knn, x, y)\n",
    "print(knn_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[337  88]\n",
      " [ 58 342]]\n"
     ]
    }
   ],
   "source": [
    "# Neural Network\n",
    "rn=MLPClassifier(max_iter=500,random_state=SEED) # Max_iter=500 porque recibí warning de convergencia\n",
    "rn_cf=KFoldConfusionMatrix(rn, x, y)\n",
    "print(rn_cf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results/results_binarization.csv\",'w+') as outfile:\n",
    "    outfile.write('\\n'.join([\n",
    "            mcToArray(dummy_cf),\n",
    "            mcToArray(dt_cf),\n",
    "            mcToArray(gnb_cf),\n",
    "            mcToArray(mnb_cf),\n",
    "            mcToArray(rf_cf),\n",
    "            mcToArray(knn_cf),\n",
    "            mcToArray(rn_cf)\n",
    "        ]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
