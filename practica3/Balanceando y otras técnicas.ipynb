{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sobre este Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este Notebook vamos a mostrar distintas técnicas que pueden servir de cara a la práctica 3:\n",
    "\n",
    "- Uso de datos no balanceados.\n",
    "- Etiquetar de forma correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabajando con datos no Balanceados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero vamos a mostrar cómo se pueden trabajar con datos no balanceados. Para ello, usaremos un paquete específico para ello: [imbalanced-learn](http://glemaitre.github.io/imbalanced-learn/install.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T12:59:59.204304Z",
     "start_time": "2020-12-15T12:59:59.196762Z"
    }
   },
   "source": [
    "Una explicación más detallada puede verse en https://towardsdatascience.com/how-to-deal-with-imbalanced-data-in-python-f9b71aba53eb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T13:05:28.021861Z",
     "start_time": "2020-12-15T13:05:28.004191Z"
    }
   },
   "source": [
    "¿Por qué es malo *aprender* con datos no balanceados?\n",
    "\n",
    "Por varios motivos:\n",
    "    \n",
    "- Si una clase está *sobrerepresentada* frente al resto, el modelo tendrá mucha tendencia a elegirlo. Esto puede ser problemático o no, si los datos finales a predecir mantienen el mismo no-balanceamiento, pero si no fuese el caso sí podría dar problemas.\n",
    "\n",
    "- Si una clase aparece poco en las muestras respecto al resto el modelo puede tener tendencia a *despreciar* dicha clase ya que le afecta poco a sus medidas, llegando incluso a ignorarla en casos extremos. Esto se produce independientemente de si dicho no-balanceamiento aparece también en los datos finales sobre los que se vaya a predecir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como comento, la gravedad depende del nivel de desbalanceamiento y de si el conjunto de datos a predecir mantiene el balanceamiento o no, pero en cualquier caso puede ser problemático, y es recomendable tratarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero antes de empezar, hay que valorar los datos que tenemos en el Datasets y el grado de balanceo. Dependendiendo de las características puede ser más conveniente uno que otro: undersampling, y oversampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T13:12:59.803803Z",
     "start_time": "2020-12-15T13:12:59.789138Z"
    }
   },
   "source": [
    "Ambas técnicas están implementadas en un paquete específico que usaremos: [imbalanced-learn](https://github.com/scikit-learn-contrib/imbalanced-learn) que está [bien documentado](http://glemaitre.github.io/imbalanced-learn/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando datos sintáticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejemplo no vamos a usar datos reales, si no datos sintéticos, Scikit-learn posee varios métodos para ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:42.697189Z",
     "start_time": "2020-12-18T09:11:42.683170Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.datasets import make_imbalance\n",
    "from sklearn.datasets import make_moons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:42.726530Z",
     "start_time": "2020-12-18T09:11:42.704930Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(n_samples=2000, shuffle=True, noise=0.5, random_state=10)\n",
    "# Le metemos \n",
    "X, y = make_imbalance(X, y,  sampling_strategy={0: 100, 1: 600}, min_c_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:42.739035Z",
     "start_time": "2020-12-18T09:11:42.729660Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero es ver cómo de desbalanceado está"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:42.759575Z",
     "start_time": "2020-12-18T09:11:42.741452Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:42.789964Z",
     "start_time": "2020-12-18T09:11:42.761897Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T13:16:37.587527Z",
     "start_time": "2020-12-15T13:16:37.577242Z"
    }
   },
   "source": [
    "Se ve que está desbalanceado, una clase aparece siete veces más que otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T13:18:53.658237Z",
     "start_time": "2020-12-15T13:18:53.648065Z"
    }
   },
   "source": [
    "##  Visualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:42.808832Z",
     "start_time": "2020-12-18T09:11:42.793481Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(X, y, title=\"Ejemplo de clases\"):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(title)\n",
    "    ax.scatter(X[y == 0, 0], X[y == 0, 1], label=\"Class #0\", alpha=0.8)\n",
    "    ax.scatter(X[y == 1, 0], X[y == 1, 1], label=\"Class #1\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.141727Z",
     "start_time": "2020-12-18T09:11:42.811204Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T13:22:49.550647Z",
     "start_time": "2020-12-15T13:22:49.541610Z"
    }
   },
   "source": [
    "De unas hay mucho más clases que de otras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T13:22:52.520804Z",
     "start_time": "2020-12-15T13:22:52.516472Z"
    }
   },
   "source": [
    "## Undersampling\n",
    "\n",
    "El undersampling es muy fácil, implica filtrar las instancias de clases que ya tengan muchos representantes. Hay varias estrategias, pero ahora aplicamos el modo por defecto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T18:16:10.561869Z",
     "start_time": "2020-12-15T18:16:10.551483Z"
    }
   },
   "source": [
    "[Documentación de la librería de undersampling](https://imbalanced-learn.readthedocs.io/en/stable/under_sampling.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Escogemos uno aleatorio primero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.149443Z",
     "start_time": "2020-12-18T09:11:43.146010Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T19:10:39.469321Z",
     "start_time": "2020-12-15T19:10:39.465078Z"
    }
   },
   "source": [
    "Es interesante el atributo **sampling_strategy**, especialmente para multiclase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.171001Z",
     "start_time": "2020-12-18T09:11:43.152852Z"
    }
   },
   "outputs": [],
   "source": [
    "# rus = RandomUnderSampler(random_state=0, sampling_strategy='majority')\n",
    "rus = NearMiss(version=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.194866Z",
     "start_time": "2020-12-18T09:11:43.174542Z"
    }
   },
   "outputs": [],
   "source": [
    "Xu, yu = rus.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.217090Z",
     "start_time": "2020-12-18T09:11:43.197980Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(yu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.659242Z",
     "start_time": "2020-12-18T09:11:43.219874Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(Xu, yu, title=\"Ejemplo de undersampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T18:22:25.351786Z",
     "start_time": "2020-12-15T18:22:25.341201Z"
    }
   },
   "source": [
    "Ahora vamos a probar con  undersampling (SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.666111Z",
     "start_time": "2020-12-18T09:11:43.661319Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.690400Z",
     "start_time": "2020-12-18T09:11:43.669297Z"
    }
   },
   "outputs": [],
   "source": [
    "Xo, yo = SMOTE().fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.715100Z",
     "start_time": "2020-12-18T09:11:43.692816Z"
    }
   },
   "outputs": [],
   "source": [
    "Counter(yo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:43.995726Z",
     "start_time": "2020-12-18T09:11:43.717281Z"
    }
   },
   "outputs": [],
   "source": [
    "plot(Xo, yo, title=\"Ejemplo de oversampling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando misma Etiqueta a varios ficheros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay que tener cuidado aplicando etiquetas a ficheros distintos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.000677Z",
     "start_time": "2020-12-18T09:11:43.997641Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T18:27:30.334348Z",
     "start_time": "2020-12-15T18:27:30.324539Z"
    }
   },
   "source": [
    "Como sólo quiero mostrar el problema de etiquetado ignoro los nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.061674Z",
     "start_time": "2020-12-18T09:11:44.002710Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.089725Z",
     "start_time": "2020-12-18T09:11:44.065254Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"test.csv\").dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T18:25:53.146463Z",
     "start_time": "2020-12-15T18:25:53.140382Z"
    }
   },
   "source": [
    "Vamos a etiquetar un atributo cualquiera, como Asientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.107643Z",
     "start_time": "2020-12-18T09:11:44.096838Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.Asientos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.129587Z",
     "start_time": "2020-12-18T09:11:44.114666Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.Asientos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forma errónea de hacerlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.148692Z",
     "start_time": "2020-12-18T09:11:44.133500Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.169429Z",
     "start_time": "2020-12-18T09:11:44.150945Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_orig = df_train.copy()\n",
    "df_test_orig = df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el etiquetado de forma independiente a cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.196788Z",
     "start_time": "2020-12-18T09:11:44.172403Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.Asientos = LabelEncoder().fit_transform(df_train_orig.Asientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.215780Z",
     "start_time": "2020-12-18T09:11:44.199369Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.Asientos = LabelEncoder().fit_transform(df_test_orig.Asientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.245152Z",
     "start_time": "2020-12-18T09:11:44.218725Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.Asientos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.268423Z",
     "start_time": "2020-12-18T09:11:44.247568Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.Asientos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.293657Z",
     "start_time": "2020-12-18T09:11:44.271250Z"
    }
   },
   "outputs": [],
   "source": [
    "for asientos in df_train_orig.Asientos.unique():\n",
    "    label_train = df_train.Asientos[df_train_orig.Asientos == asientos].unique()\n",
    "    label_test = df_test.Asientos[df_test_orig.Asientos == asientos].unique()\n",
    "    \n",
    "    \n",
    "    if len(label_train)==0 or len(label_test)==0:\n",
    "        continue\n",
    "    \n",
    "    if label_train != label_test:\n",
    "        print(\"Error, {} es etiquetado en train como {} y en test como {}\".format(asientos, label_train[0], label_test[0]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ese problema puede hacer que las predicciones sobre el de test sean mucho peores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-15T18:54:59.100235Z",
     "start_time": "2020-12-15T18:54:59.095507Z"
    }
   },
   "source": [
    "## Forma correcta de hacerlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La solución sería aprender a partir del fichero del mismo nombre con todos los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero aprendemos las etiquetas a partir de todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.322358Z",
     "start_time": "2020-12-18T09:11:44.296362Z"
    }
   },
   "outputs": [],
   "source": [
    "labelAsientos = LabelEncoder().fit(pd.read_csv(\"asientos.csv\").Asientos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usamos el mismo labelAsientos a ambos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.352584Z",
     "start_time": "2020-12-18T09:11:44.325400Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.Asientos = labelAsientos.transform(df_train_orig.Asientos)\n",
    "df_test.Asientos = labelAsientos.transform(df_test_orig.Asientos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.377644Z",
     "start_time": "2020-12-18T09:11:44.355008Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.Asientos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.397854Z",
     "start_time": "2020-12-18T09:11:44.380305Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test.Asientos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora si comprobamos de nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:12:49.707112Z",
     "start_time": "2020-12-18T09:12:49.664622Z"
    }
   },
   "outputs": [],
   "source": [
    "correcto = True\n",
    "\n",
    "for asientos in df_train_orig.Asientos.unique():\n",
    "    label_train = df_train.Asientos[df_train_orig.Asientos == asientos].unique()\n",
    "    label_test = df_test.Asientos[df_test_orig.Asientos == asientos].unique()\n",
    "    \n",
    "    if len(label_train)==0 or len(label_test)==0:\n",
    "        continue\n",
    "    \n",
    "    if label_train != label_test:\n",
    "        print(\"Error, {} es etiquetado en train como {} y en test como {}\".format(asientos, label_train, label_test))\n",
    "        correcto = False\n",
    "        break\n",
    "        \n",
    "if correcto:\n",
    "    print(\"Todo perfecto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que ahora las etiquetas coinciden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T09:18:05.201390Z",
     "start_time": "2020-12-16T09:18:05.196642Z"
    }
   },
   "source": [
    "## Generando el fichero para Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos un modelo ya aprendido de entrenamiento, con el preprocesado deseado, lo que se pide es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T09:11:44.481543Z",
     "start_time": "2020-12-18T09:11:44.435099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Si tenemos model ya aprendido\n",
    "# model = ....\n",
    "data_test = pd.read_csv(\"test.csv\")\n",
    "# Preprocesamos data_test\n",
    "# Eliminamos el campo id ya que no se debe usar para predecir\n",
    "ids = data_test['id']\n",
    "del data_test['id']\n",
    "# Ahora predecimos\n",
    "predict = model.predict(data_test)\n",
    "# Generamos \n",
    "df_result = pd.DataFrame({'id': ids, 'Precio_cat': predict})\n",
    "df_result.to_csv(\"mis_resultados.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota:** El código anterior es un borrador, no es seguro que funcione ya que no lo he podido probar por no tener el model creado."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
